<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">

<script async="" src="https://www.google-analytics.com/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88403851-1', 'auto');
  ga('send', 'pageview');

</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.3/jquery.min.js"></script> 
<script src="page.js"></script> 
<link rel="stylesheet" href="style.css">
<link href="https://fonts.googleapis.com/css?family=Open+Sans:400,300" rel="stylesheet" type="text/css">
<title>Jason Lang/title>
</head>
<body>
<div id="content">  
  <div id="title">
    <h1>Jason Lang</h1>
    <p>
      Reinforment Learning Researcher<br>
      beysenba<span style="display:none">spam</span>@cs.cmu.edu
    </p>
  </div>

  <!-- links -->
  <div class="container" id="links">
  <p></p><hr><p></p>
  <p>
    <a href="#research">Research</a>
    <a href="#teaching">Teaching</a>
    <a href="#blog">Blog</a>
    <a href="#projects">Projects</a>
    <a href="resume.pdf">Resume</a>
    <a href="https://calendar.google.com/calendar/embed?src=eysenbachbe%40gmail.com&amp;title=Ben%20Eysenbach&amp;showPrint=0">Calendar</a>
  </p>
  <br>
  <p></p><hr width="100%"><p></p>
  </div>


  <div class="container" style="margin: 0px 20px">
	<p>I am an undergraduate Mechanical Engineering student at Virginia Tech and a Machine Learning researcher at the Virginia Tech Research Center in Arlington. 
 	</p>
    <hr>
   </div>
<br>

  <!--
  <div class="container" id="news">
    <h2>News</h2>
    <table id="news-table" style="padding: 0px 20px"></table>
    <hr>
  </div>
  -->


  <div class="container" id="research">
    <h2>Research</h2>
    <table id="research-table"><tbody><tr><td class="image-td"><img class="project-img" src="images/sorb.png"></td><td class="description-td"><h3>Search on the Replay Buffer: Bridging Motion Planning and Reinforcement Learning</h3><p><i>Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine</i></p><p>The history of learning for control has been an exciting back and forth between two broad classes of algorithms: planning and reinforcement learning. We introduce a general-purpose control algorithm that combines the strengths of planning and reinforcement learning to solve long-horizon, sparse-reward tasks. Using graph search over our replay buffer, we can automatically generate a sequence of subgoals, even in image-based environments. Our algorithm, search on the replay buffer (SoRB), enables agents to solve sparse reward tasks over one hundred steps, and generalizes substantially better than standard RL algorithms. ICLR 2019 Workshop on Structures and Priors in RL. [<a href="https://arxiv.org/pdf/1906.05253.pdf">paper</a>, <a href="http://bit.ly/rl_search">code (runs in your browser!)</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/smm_ant.png"></td><td class="description-td"><h3>Efficient Exploration via State Marginal Matching</h3><p><i>Lisa Lee*, Benjamin Eysenbach*, Emilio Parisotto*, Eric Xing, Sergey Levine, Ruslan Salakhutdinov</i></p><p>We suggest that the goal of exploration should be to maximize entropy over states, and show that this method works well on simulated robotic tasks. We also discuss how prior work on explorationcan almost maximizes some entropy, but omits a crucial historical averaging step. ICLR 2019 Workshop on Structures and Priors in RL (oral) and Workshop on Task Agnostic RL (oral). [<a href="https://arxiv.org/pdf/1906.05274.pdf">paper</a>, <a href="https://sites.google.com/view/state-marginal-matching">website</a>, <a href="https://github.com/RLAgent/state-marginal-matching">code</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/unknown_rewards.png"></td><td class="description-td"><h3>Reinforcement Learning with Unknown Reward Functions</h3><p><i>Benjamin Eysenbach*, Jacob Tyo*, Shixiang Gu, Ruslan Salakhutdinov, Sergey Levine</i></p><p>In this project, we propose a method for learning useful skills without a reward function. Our simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. ICLR 2019 Workshop on Structures and Priors in RL (oral) and Workshop on Task Agnostic RL. [<a href="https://spirl.info/2019/camera-ready/spirl_camera-ready_26.pdf">paper</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/diayn.gif"></td><td class="description-td"><h3>Diversity Is All You Need: Learning Diverse Skills Without a Reward Function</h3><p><i>Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, Sergey Levine</i></p><p>In this project, we propose a method for learning useful skills without a reward function. Our simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. Accepted to ICLR 2019. [<a href="https://arxiv.org/pdf/1802.06070">paper</a>, <a href="https://sites.google.com/view/diayn/home">website</a>, <a href="https://github.com/ben-eysenbach/sac">code</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/sectar.png"></td><td class="description-td"><h3>Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings</h3><p><i>John D Co-Reyes, YuXuan Liu, Abhishek Gupta, Benjamin Eysenbach, Pieter Abbeel, Sergey Levine</i></p><p>We take a representation learning perspective on hierarchical reinforcement learning, where the problem of learning lower layers in a hierarchy is transformed into the problem of learning trajectory-level generative models. We show that we can learn continuous latent representations of trajectories, which are effective in solving temporally extended and multi-stage problems. Accepted to ICML 2018. [<a href="http://proceedings.mlr.press/v80/co-reyes18a.html">paper</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/lnt.gif"></td><td class="description-td"><h3>Leave No Trace: Learning to Reset for Safe and Autonomous Reinforcement Learning</h3><p><i>Benjamin Eysenbach, Shixiang Gu, Julian Ibarz, Sergey Levine</i></p><p>In this work, we propose an autonomous method for safe and efficient reinforcement learning that simultaneously learns a forward and reset policy, with the reset policy resetting the environment for a subsequent attempt. The reset policy can avoid manual resets, can reduce the number of unsafe actions, and can automatically induce a curriculum. Accepted to ICLR 2018. [<a href="https://arxiv.org/abs/1711.06782">paper</a>, <a href="https://sites.google.com/site/mlleavenotrace/">website</a>, <a href="https://github.com/brain-research/LeaveNoTrace">code</a>]<br><a href="https://www.technologyreview.com/the-download/609562/robots-get-an-undo-button-that-could-help-them-learn-faster/"><img src="images/tr.png" width="50px"></a></p></td></tr><tr><td class="image-td"><img class="project-img" src="images/mistaken.png"></td><td class="description-td"><h3>Who is Mistaken?</h3><p><i>Benjamin Eysenbach, Carl Vondrick, Antonio Torralba</i></p><p>In this project, I studied the beliefs of people in videos. Using a dataset I collected on Mechanical Turk, I created a representation of characters' beliefs for recognizing mistaken characters. Diagnostics on my model suggest it learns important cues for recognizing mistaken beliefs, such as gaze and the arrow of time. [<a href="http://people.csail.mit.edu/bce/mistaken/">website</a>, <a href="https://arxiv.org/pdf/1612.01175v1.pdf">paper</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/clustervision.png"></td><td class="description-td"><h3>Clustervision: Visual Supervision of Unsupervised Clustering</h3><p><i>Bum Chul Kwon, Ben Eysenbach, Janu Verma, Kenney Ng, Christopher De Filippi, Walter F Stewart, Adam Perer</i></p><p>Designed algorithms for Clustervision, a visual analytics tool that helps ensure data scientists find the right clustering among the large amount of techniques and parameters available. Accepted at IEEE Transactions on Visualization and Computer Graphics. [<a href="http://perer.org/papers/adamPerer-Clustervision-VAST2017.pdf">paper</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/segment.png"></td><td class="description-td"><h3>Video Segmentation</h3><p>Applied deep learning to video segmentation, and implemented image segmentation in JS.  I gave a talk about this project at EECScon 2015, an MIT undergrad conference [2nd place]. [<a href="http://web.mit.edu/bce/www/segment/">demo</a>, <a href="http://web.mit.edu/bce/www/segment_poster.pdf">poster</a>, <a href="http://web.mit.edu/bce/www/segment_slides.pdf">slides</a>, <a href="http://people.csail.mit.edu/bce/readme.html">code</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/uav_small.jpg"></td><td class="description-td"><h3>Autonomous Quadcopters for Aerial Imaging</h3><p>Worked on image analysis and system integration for a research project in the <a href="http://senseable.mit.edu/">Sensible City Lab</a>. [<a href="http://www.dynsyslab.org/portfolio/waterfly/">site</a>, <a href="https://www.youtube.com/watch?v=a0ec5aS_NeA">video</a>]</p></td></tr></tbody></table>
    <hr>
  </div>

  <div class="container" id="teaching">
    <h2>Teaching</h2>
    <table id="teaching-table"><tbody><tr><td class="image-td"><img class="project-img" src="images/rl.jpg"></td><td class="description-td"><h3><a href="https://cmudeeprl.github.io/703website/">10-703: Deep Reinforcement Learning</a></h3><p>Head TA in Fall 2019.</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/stockholm.jpg"></td><td class="description-td"><h3>Exploration in Reinforcement Learning: Workshop @ ICML 2018, ICML 2019</h3><p><a href="https://github.com/suryabhupa">Surya Bhupatiraju</a> and I co-organized a workshop on Exploration in Reinforcement Learning at <a href="" https:="" icml.cc="" "="">ICML 2018 and ICML 2019</a>.</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/6008.jpg"></td><td class="description-td"><h3><a href="http://web.mit.edu/6.008/www/">6.008: Introduction to Inference</a></h3><p>TA in Fall 2016</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/6042.jpg"></td><td class="description-td"><h3><a href="http://mit.edu/6.042/">6.042: Math for Computer Science</a></h3><p>TA in Spring 2015</p></td></tr></tbody></table>
    <hr>
  </div>
 
 
  <div class="container" id="blog">
    <h2>Blog</h2>
    <table id="blog-table"><tbody><tr><td class="image-td"><img class="project-img" src="images/stockholm.jpg"></td><td class="description-td"><h3><a href="https://medium.com/@erl.leads/hitchhikers-guide-to-organizing-an-academic-workshop-cc9a5b1c32c9">Hitchhiker's Guide to Organizing an Academic Workshop</a></h3><p>Surya Bhupatiraju and I discuss what went well at our Workshop on Exploration in RL, and what we learned.</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/residency.jpg"></td><td class="description-td"><h3><a href="https://colinraffel.com/blog/writing-a-google-ai-residency-cover-letter.html">Writing a Google AI Residency Cover Letter</a></h3><p>Katherine Lee and I explain how to write a cover letter for AI residency programs.</p></td></tr></tbody></table>
    <hr>
  </div>


  <div class="container" id="projects">
    <h2>Class Projects</h2>
    <table id="projects-table"><tbody><tr><td class="image-td"><img class="project-img" src="images/6882.png"></td><td class="description-td"><h3>Topic Modeling of Academic Papers at MIT</h3><p>For Bayesian Modeling (<a href="http://www.tamarabroderick.com/course_6_882.html">6.882</a>), applied LDA to a new dataset of 100,000+ academic papers written by MIT affiliates. [<a href="http://web.mit.edu/bce/www/lda.pdf">paper</a>, <a href="https://github.com/ben-eysenbach/6.882-LDA">code</a>, <a href="https://github.com/ben-eysenbach/6.882-LDA/blob/master/datasets/dspace.tar.gz?raw=true">data</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/mmbm.png"></td><td class="description-td"><h3>Presentations on Gaussian Processes and Mixed Membership Block Models</h3><p>For a seminar on Bayesian Modeling (<a href="http://www.tamarabroderick.com/course_6_882.html">6.882</a>), taught classes on Gaussian Processes and Mixed Membership Block Models. [<a href="https://docs.google.com/presentation/d/1V_rzvHggMqnTNOKzjUvs6EMmaH4qVhYLcRv4CbqHrLI/edit?usp=sharing">GP slides</a>, <a href="https://docs.google.com/presentation/d/1zWM9a_uAeBR_72m4hPkyQOxXoYV_i1FZhfKvE5_5jt8/edit?usp=sharing">MMBM slides</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/6854_small.jpg"></td><td class="description-td"><h3>Exact Recovery of Stochastic Block Models</h3><p>Wrote a survey paper on exact recovery for Advanced Algorithms (<a href="http://people.csail.mit.edu/moitra/854.html">6.854</a>). [<a href="http://web.mit.edu/bce/www/sbm.pdf">paper</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/dna.png"></td><td class="description-td"><h3>DNA Compression with Graphical Models</h3><p>For Algorithms for Inference (6.438), I implemented developed a model for compressing shotgun DNA sequences using LDPC codes. [<a href="http://web.mit.edu/bce/www/6.438_project.pdf">paper</a>, <a href="http://web.mit.edu/bce/www/6.438_project.zip">code</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/cipher.jpg"></td><td class="description-td"><h3>Cipher Breaking using MCMC</h3><p>For Inference and Information (6.437), I implemented a model for breaking substitution ciphers using the Metropolis Hastings algorithm. [<a href="http://web.mit.edu/bce/www/6.437_project.pdf">paper</a>, <a href="http://web.mit.edu/bce/www/6.437_project.zip">code</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/6856.jpg"></td><td class="description-td"><h3>Randomized Splay Trees</h3><p>For Randomized Algorithms (<a href="https://courses.csail.mit.edu/6.856/current/">6.856</a>), implemented and analyzed randomized splay trees. Collaborated with Robi Bhattacharjee. [<a href="http://web.mit.edu/bce/www/6856_paper.pdf">paper</a>, <a href="http://web.mit.edu/bce/www/6856_code.zip">code</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/6819.png"></td><td class="description-td"><h3>Visualizing 3D Reconstruction</h3><p>For Computer Vision (<a href="http://6.869.csail.mit.edu/fa14/">6.819</a>), used an Oculus Rift to visualize algorithms which reconstruct a 3D scene from images. Collaborated with <a href="https://github.com/andrewmo2014">Andrew Moran</a>. [<a href="http://web.mit.edu/bce/www/6819_paper.pdf">paper</a>, <a href="http://web.mit.edu/bce/www/6819_slides.pdf">slides</a>, <a href="http://web.mit.edu/bce/www/6819_video.mov">video</a>]</p></td></tr><tr><td class="image-td"><img class="project-img" src="images/hubway_small.jpg"></td><td class="description-td"><h3>Biking in Boston</h3><p>Warped maps to reflect distances according to cyclists. Part of a data visualization project on how Hubway for Applying Media Technologies (CMS.622). [<a href="http://people.csail.mit.edu/bce/hubway">site</a>, <a href="http://web.mit.edu/bce/www/cms622_hubway.html">code</a>]</p></td></tr></tbody></table>
    <hr>
  </div>

 
  <div class="container">
    <p id="copyright">© 2019 Ben Eysenbach</p>
  </div>


<!-- spacer to expand content div -->
<div class="spacer" style="clear: both;"></div>
</div> <!-- end container div -->
</body>
</html>